# Understanding Gradient Descent with Python

---
_ODSC West 2019_
_Author: Nico Van de Bovenkamp_

## By the end of this lession you will

- Understand the fundamentals of Machine Learning optimization with gradient descent
- Understand basic implementations of gradient and stochastic gradient descent 
- Be able to implement your own simple linear and logistic regression using gradient descent in Python

- Understand the fundamentals of logistic regression
- Be able to implement your own model class that's just like sci-kit learns

### Getting Setup

**You will need to use Git to get access to the materials.** If you do not remember or do not have a github account, please use this [link](https://help.github.com/en/github/getting-started-with-github/signing-up-for-a-new-github-account) to set one up!

**You will use git clone to pull these down.** For information on git clone, see this [link](https://www.atlassian.com/git/tutorials/setting-up-a-repository/git-clone). 

`git clone https://github.com/nicojvdb/odsc-west-2019-python-gradient-descent.git`

We will be using the following packages:
* JupyterLab (or Jupyter Notebooks, either is fine)
* Numpy
* Pandas
* Sci-kit Learn
* Matplotlib

**For information on setting up Anaconda**: see this [link](https://www.datacamp.com/community/tutorials/installing-anaconda-mac-os-x).

**_Note_**: You are free to use whatever package manager you would like!

### Section 1: Modeling basics, gradient descent, linear regression

**Notebook**: `session/gradients.ipynb`

### Section 2: Applying learnings to logistic regression and a model class

**Notebook**: `session/building_own_model_class.ipynb`

### Solutions

Sample solutions are laid out in the `/solutions` directory.
